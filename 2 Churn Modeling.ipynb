{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial Neural Network\n",
    "\n",
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nakhon\\Anaconda3\\envs\\t81_558_deep_learning\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\nakhon\\Anaconda3\\envs\\t81_558_deep_learning\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4796 - acc: 0.7957\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4142 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4041 - acc: 0.8167\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3943 - acc: 0.8294\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3862 - acc: 0.8304\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3805 - acc: 0.8356\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3754 - acc: 0.8451\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3720 - acc: 0.8469\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3695 - acc: 0.8504\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3676 - acc: 0.8512\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3649 - acc: 0.8507\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3632 - acc: 0.8512\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3615 - acc: 0.8529\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3601 - acc: 0.8525\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3600 - acc: 0.8539\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3587 - acc: 0.8544\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3567 - acc: 0.8554\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3565 - acc: 0.8557\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3562 - acc: 0.8544\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3551 - acc: 0.8549\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3541 - acc: 0.8592\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3543 - acc: 0.8556\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3540 - acc: 0.8585\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3538 - acc: 0.8555\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3533 - acc: 0.8559\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3527 - acc: 0.8575\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3527 - acc: 0.8580: 0s - loss: 0.3688 - ac\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3518 - acc: 0.8589\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3520 - acc: 0.8572\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3526 - acc: 0.8589\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3520 - acc: 0.8584\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3514 - acc: 0.8569\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3514 - acc: 0.8584\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3509 - acc: 0.8570\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3515 - acc: 0.8575\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3505 - acc: 0.8580\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3506 - acc: 0.8569\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3511 - acc: 0.8584\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3508 - acc: 0.8587\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3502 - acc: 0.8572\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3505 - acc: 0.8571\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3506 - acc: 0.8572\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3500 - acc: 0.8574\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3501 - acc: 0.8584\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3489 - acc: 0.8600\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3500 - acc: 0.8575\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3497 - acc: 0.8592\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3500 - acc: 0.8580\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3492 - acc: 0.8601\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3499 - acc: 0.8579\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3495 - acc: 0.8585\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3495 - acc: 0.8562\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3492 - acc: 0.8585\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3476 - acc: 0.8580\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3496 - acc: 0.8586\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3490 - acc: 0.8575\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3491 - acc: 0.8562\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3479 - acc: 0.8591\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3482 - acc: 0.8561\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3486 - acc: 0.8587\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3482 - acc: 0.8587\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3474 - acc: 0.8597\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3480 - acc: 0.8571\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3477 - acc: 0.8577\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3479 - acc: 0.8570\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3472 - acc: 0.8585\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3474 - acc: 0.8576\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3478 - acc: 0.8580\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3467 - acc: 0.8585\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3471 - acc: 0.8580\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3468 - acc: 0.8579\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3474 - acc: 0.8590\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3475 - acc: 0.8604\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3466 - acc: 0.8609\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3475 - acc: 0.8585\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3478 - acc: 0.8572\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3464 - acc: 0.8611\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3467 - acc: 0.8616\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3469 - acc: 0.8585\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3463 - acc: 0.8611\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3465 - acc: 0.8575\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3468 - acc: 0.8596\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3463 - acc: 0.8594: 0s - loss: 0.3497 - acc: 0.\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3459 - acc: 0.8589\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3458 - acc: 0.8576\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3459 - acc: 0.8607\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3452 - acc: 0.8591\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3455 - acc: 0.8602\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3454 - acc: 0.8594\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3456 - acc: 0.8587\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3448 - acc: 0.8592\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3452 - acc: 0.8577\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3450 - acc: 0.8585\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3449 - acc: 0.8621\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3450 - acc: 0.8600\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3449 - acc: 0.8609\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3447 - acc: 0.8596\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3452 - acc: 0.8595\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3439 - acc: 0.8631\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3446 - acc: 0.8596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28290b95f28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Making predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1532   63]\n",
      " [ 207  198]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Source: http://scikit-learn.org/stable/auto_examples/model_selection/\n",
    "#         plot_confusion_matrix.html#confusion-matrix\n",
    "\n",
    "\n",
    "# y_test = np.array([1, 1, 0, 1])\n",
    "# y_train = np.array([0, 0, 1, 1])\n",
    "\n",
    "# y_test_pred = np.array([1, 1, 0, 1])  # from classifier_logistic.predict(x_test)\n",
    "# y_train_pred = np.array([0, 1, 0, 1]) # from classifier_logistic.predict(x_train)\n",
    "\n",
    "# y_true = np.concatenate((y_train, y_test))\n",
    "# y_pred = np.concatenate((y_train_pred, y_test_pred))\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,  normalize=False,  title='Confusion matrix',  cmap=plt.cm.Blues):\n",
    "            \"\"\"\n",
    "            This function prints and plots the confusion matrix.\n",
    "            Normalization can be applied by setting `normalize=True`.\n",
    "            \"\"\"\n",
    "            if normalize:\n",
    "                cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "                print(\"Normalized confusion matrix\")\n",
    "            else:\n",
    "                print('Confusion matrix, without normalization')\n",
    "\n",
    "            print(cm)\n",
    "\n",
    "            plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "            plt.title(title)\n",
    "            plt.colorbar()\n",
    "            tick_marks = np.arange(len(classes))\n",
    "            plt.xticks(tick_marks, classes, rotation=45)\n",
    "            plt.yticks(tick_marks, classes)\n",
    "\n",
    "            fmt = '.2f' if normalize else 'd'\n",
    "            thresh = cm.max() / 2.\n",
    "            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "                plt.text(j, i, format(cm[i, j], fmt),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.ylabel('True label')\n",
    "            plt.xlabel('Predicted label')\n",
    "\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=[0, 1], title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
